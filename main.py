import os
from src.parser import HybridDocumentParser
from src.chunker import optimized_korean_chunking
from src.evaluator import ChunkEvaluator

def main():
    # 1. ì„¤ì •
    input_pdf = "RAG_TEST_DATA/2014_08.pdf" # í…ŒìŠ¤íŠ¸í•  PDF ê²½ë¡œ
    output_dir = "output"
    output_md = os.path.join(output_dir, "processed_doc.md")

    if not os.path.exists(input_pdf):
        print(f"âš ï¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {input_pdf}")
        # return (for verification flow, we might want to proceed or warn, but existing logic returns)
        # However, if we want to test even without file, we might need a dummy mode, but sticking to file check is safer.
        return

    os.makedirs(output_dir, exist_ok=True)

    # 2. íŒŒì„œ ì´ˆê¸°í™” ë° ì‹¤í–‰
    parser = HybridDocumentParser()
    markdown_content = parser.parse(input_pdf)

    # 3. ì¤‘ê°„ ê²°ê³¼ ì €ì¥ (ë””ë²„ê¹…ìš©)
    with open(output_md, "w", encoding="utf-8") as f:
        f.write(markdown_content)
    print(f"ğŸ’¾ Parsed markdown saved to {output_md}")

    # 4. ì²­í‚¹ ì‹¤í–‰
    chunks = optimized_korean_chunking(markdown_content)

    # 5. ê²°ê³¼ í™•ì¸ ë° í‰ê°€
    evaluator = ChunkEvaluator(chunks)
    evaluator.analyze()
    evaluator.save_report(output_dir)

    print("\n--- [Preview Chunks] ---")
    for i, chunk in enumerate(chunks[:10]):
        print(f"\nğŸ§© Chunk #{i+1}")
        print(f"Metadata: {chunk.metadata}")
        print(f"Content: {chunk.page_content[:250]}...") # ì•ë¶€ë¶„ë§Œ ì¶œë ¥
        print("-" * 50)

if __name__ == "__main__":
    main()
